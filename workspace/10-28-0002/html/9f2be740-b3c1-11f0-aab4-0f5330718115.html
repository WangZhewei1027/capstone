<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>K-Means Clustering</title>
  <style>
    :root {
      --bg: #0f1221;
      --panel: #171b31;
      --text: #e7ebff;
      --muted: #aab3d5;
      --accent: #7aa2ff;
      --accent2: #7fffd4;
      --accent3: #ff9f7a;
      --code: #0c0f1a;
      --border: #2a3158;
    }
    * { box-sizing: border-box; }
    html, body {
      margin: 0;
      background: var(--bg);
      color: var(--text);
      font-family: system-ui, -apple-system, Segoe UI, Roboto, Ubuntu, Cantarell, Noto Sans, Arial, "Apple Color Emoji", "Segoe UI Emoji";
      line-height: 1.6;
    }
    header {
      padding: 2.5rem 1rem 1rem;
      text-align: center;
    }
    h1 {
      margin: 0 0 .25rem 0;
      font-size: clamp(1.8rem, 3vw, 2.4rem);
      letter-spacing: .3px;
    }
    header p {
      margin: 0;
      color: var(--muted);
      font-size: 0.98rem;
    }
    main {
      max-width: 900px;
      margin: 0 auto;
      padding: 1rem;
      display: grid;
      gap: 1rem;
    }
    section, aside {
      background: var(--panel);
      border: 1px solid var(--border);
      border-radius: 12px;
      padding: 1rem 1.1rem;
    }
    h2 {
      margin-top: 0;
      font-size: 1.2rem;
    }
    ul { margin: .5rem 0 .25rem 1.2rem; }
    li { margin: .2rem 0; }
    code, pre {
      font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, "Liberation Mono", monospace;
      font-size: .92rem;
    }
    pre {
      background: var(--code);
      border: 1px solid var(--border);
      border-radius: 10px;
      padding: .9rem;
      overflow: auto;
    }
    .grid {
      display: grid;
      grid-template-columns: 1fr;
      gap: 1rem;
    }
    @media (min-width: 840px) {
      .grid {
        grid-template-columns: 1.2fr .8fr;
      }
    }
    .pill {
      display: inline-block;
      background: #0e1733;
      border: 1px solid var(--border);
      color: var(--accent);
      padding: .2rem .55rem;
      border-radius: 999px;
      font-size: .82rem;
      margin-right: .35rem;
    }
    .figure {
      background: #0c1126;
      border: 1px dashed #2a3158;
      border-radius: 10px;
      padding: .75rem;
    }
    .legend {
      display: flex;
      gap: .75rem;
      flex-wrap: wrap;
      font-size: .9rem;
      color: var(--muted);
      margin-top: .5rem;
    }
    .dot { width: .7rem; height: .7rem; border-radius: 50%; display: inline-block; vertical-align: middle; margin-right: .35rem; }
    .dot.c1 { background: var(--accent); }
    .dot.c2 { background: var(--accent2); }
    .dot.c3 { background: var(--accent3); }
    a { color: #9ec1ff; text-decoration: none; }
    a:hover { text-decoration: underline; }
    footer {
      max-width: 900px;
      margin: 0 auto;
      padding: 1rem;
      color: var(--muted);
      text-align: center;
      font-size: .9rem;
    }
  </style>
</head>
<body>
  <header>
    <h1>K-Means Clustering</h1>
    <p>Partition n observations into k clusters by minimizing within-cluster variance</p>
  </header>

  <main>
    <div class="grid">
      <section>
        <h2>What is K-Means?</h2>
        <p>
          K-Means is an unsupervised learning algorithm that groups data into k clusters.
          It assumes clusters are roughly spherical in feature space and aims to minimize the sum of squared distances from points to their assigned cluster centroids.
        </p>

        <div class="figure" aria-label="Illustrative 2D clustering with three clusters and centroids">
          <svg viewBox="0 0 600 300" width="100%" height="220" role="img" aria-labelledby="fig-title">
            <title id="fig-title">Three clusters with centroids (X)</title>
            <rect x="0" y="0" width="600" height="300" fill="#0c1126"></rect>

            <!-- Cluster 1 (blue) -->
            <g fill="#7aa2ff">
              <circle cx="120" cy="160" r="5"></circle>
              <circle cx="150" cy="140" r="5"></circle>
              <circle cx="130" cy="120" r="5"></circle>
              <circle cx="165" cy="165" r="5"></circle>
              <circle cx="140" cy="180" r="5"></circle>
              <circle cx="110" cy="135" r="5"></circle>
            </g>
            <!-- Centroid 1 -->
            <g stroke="#7aa2ff" stroke-width="3">
              <line x1="145" y1="145" x2="160" y2="160"></line>
              <line x1="160" y1="145" x2="145" y2="160"></line>
            </g>

            <!-- Cluster 2 (mint) -->
            <g fill="#7fffd4">
              <circle cx="300" cy="70" r="5"></circle>
              <circle cx="330" cy="85" r="5"></circle>
              <circle cx="315" cy="110" r="5"></circle>
              <circle cx="345" cy="95" r="5"></circle>
              <circle cx="285" cy="95" r="5"></circle>
              <circle cx="325" cy="65" r="5"></circle>
            </g>
            <!-- Centroid 2 -->
            <g stroke="#7fffd4" stroke-width="3">
              <line x1="316" y1="90" x2="331" y2="105"></line>
              <line x1="331" y1="90" x2="316" y2="105"></line>
            </g>

            <!-- Cluster 3 (orange) -->
            <g fill="#ff9f7a">
              <circle cx="470" cy="210" r="5"></circle>
              <circle cx="500" cy="220" r="5"></circle>
              <circle cx="520" cy="200" r="5"></circle>
              <circle cx="490" cy="240" r="5"></circle>
              <circle cx="515" cy="235" r="5"></circle>
              <circle cx="545" cy="215" r="5"></circle>
            </g>
            <!-- Centroid 3 -->
            <g stroke="#ff9f7a" stroke-width="3">
              <line x1="505" y1="220" x2="520" y2="235"></line>
              <line x1="520" y1="220" x2="505" y2="235"></line>
            </g>
          </svg>
          <div class="legend">
            <span><span class="dot c1"></span>Cluster A</span>
            <span><span class="dot c2"></span>Cluster B</span>
            <span><span class="dot c3"></span>Cluster C</span>
            <span>Centroids marked by X</span>
          </div>
        </div>

        <h2>How it works</h2>
        <ol>
          <li>Choose k, the number of clusters.</li>
          <li>Initialize k centroids (randomly or with k-means++).</li>
          <li>Assignment step: assign each point to the nearest centroid.</li>
          <li>Update step: recompute each centroid as the mean of its assigned points.</li>
          <li>Repeat steps 3–4 until assignments stop changing or improvement is below a threshold.</li>
        </ol>

        <h2>Pseudocode</h2>
        <pre><code>input: data X ∈ R^(n×d), clusters k, max_iter, tol
initialize centroids μ₁..μ_k  (e.g., k-means++)

for t in 1..max_iter:
    # assignment
    for i in 1..n:
        c[i] ← argmin_j ||X[i] - μ_j||²

    # update
    for j in 1..k:
        S_j ← { i | c[i] = j }
        if S_j not empty:
            μ_j ← mean of X over indices in S_j

    # check convergence
    if change in μ is &lt; tol:
        break

return assignments c, centroids μ</code></pre>

        <h2>Key parameters</h2>
        <p>
          <span class="pill">k (clusters)</span>
          <span class="pill">init (random, k-means++)</span>
          <span class="pill">max_iter</span>
          <span class="pill">n_init (restarts)</span>
          <span class="pill">tol (convergence)</span>
          <span class="pill">metric (typically Euclidean)</span>
        </p>

        <h2>When to use</h2>
        <ul>
          <li>Quick, scalable clustering for roughly spherical, similarly sized groups.</li>
          <li>Feature learning or compression (cluster centroids as prototypes).</li>
          <li>Initialization for other algorithms (e.g., GMM with EM).</li>
        </ul>
      </section>

      <aside>
        <h2>Tips and caveats</h2>
        <ul>
          <li>Initialization matters. Use k-means++ and multiple restarts to reduce local minima.</li>
          <li>Scale features. Differences in units can dominate Euclidean distance.</li>
          <li>Choose k via elbow method, silhouette score, or domain knowledge.</li>
          <li>Sensitive to outliers; consider trimming or robust alternatives.</li>
          <li>Non-spherical or varying-density clusters may be better handled by DBSCAN or spectral clustering.</li>
        </ul>

        <h2>Complexity</h2>
        <p>Per iteration: O(n × k × d). Total cost scales with number of iterations until convergence.</p>

        <h2>Resources</h2>
        <ul>
          <li><a href="https://en.wikipedia.org/wiki/K-means_clustering" target="_blank" rel="noopener">Wikipedia: K-means clustering</a></li>
          <li><a href="https://scikit-learn.org/stable/modules/clustering.html#k-means" target="_blank" rel="noopener">scikit-learn: KMeans</a></li>
          <li><a href="https://theory.stanford.edu/~sergei/papers/kMeansPP-soda.pdf" target="_blank" rel="noopener">k-means++ paper (Arthur &amp; Vassilvitskii, 2007)</a></li>
        </ul>
      </aside>
    </div>
  </main>

  <footer>
    © 2025 K-Means Clustering — Simple overview and illustration
  </footer>
</body>
</html>